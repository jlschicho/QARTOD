{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOS\n",
    "## Plot the results of the GLOS QARTOD QC Tests\n",
    "\n",
    "### Procedure\n",
    "* Connect to GLOS OPeNDAP endpoints\n",
    "* Get raw wave height data from stations of interest\n",
    "* Plot raw data and QC'ed data for a series of QC tests\n",
    "\n",
    "### Primary flags for QARTOD\n",
    "\n",
    "    GOOD_DATA = 1\n",
    "    UNKNOWN = 2\n",
    "    SUSPECT = 3\n",
    "    BAD_DATA = 4\n",
    "    MISSING = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "from urllib.parse import quote\n",
    "import qc\n",
    "import quantities as q\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "#from IPython import embed\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import folium\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(bounding_box):\n",
    "    \"\"\"Create bounding box coordinates for the map.\"\"\"\n",
    "    coordinates = []\n",
    "    coordinates.append([bounding_box[1], bounding_box[0]])\n",
    "    coordinates.append([bounding_box[1], bounding_box[2]])\n",
    "    coordinates.append([bounding_box[3], bounding_box[2]])\n",
    "    coordinates.append([bounding_box[3], bounding_box[0]])\n",
    "    coordinates.append([bounding_box[1], bounding_box[0]])\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to OPeNDAP Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Glos_url='http://tds.glos.us/thredds/dodsC/buoy_agg_standard_qc/'\n",
    "station_ids=['45024','45022','45174','45170']  ##45014 has only 35 time steps and glerlwe13 doesn't have any data in the time range chosen (oct 22-oct 29)\n",
    "                         ##45013,glerlwe8, glerlwe4, glerlwe2, and UMBIO have NaN values for \n",
    "                         #Significant Wave Height (October 2017) or no sig wave height variable\n",
    "bbox=[[-93.186, 40.1956], [-74.992, 49.511]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Flag Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_lats=[]\n",
    "all_lons=[]\n",
    "for station_id in station_ids:\n",
    "    file_url=Glos_url+station_id+'/'+station_id+'.ncml'\n",
    "    xr_dataset=xr.open_dataset(file_url)\n",
    "    print(station_id+'***********************************************************************')\n",
    "    \n",
    "    arr=xr_dataset.sel(time=slice('2017-10-22','2017-10-29')).variables\n",
    "    arr_slice=xr_dataset.sel(time=slice('2017-10-22','2017-10-29'))\n",
    "    obs_df = xr_dataset.sel(time=slice('2017-10-22','2017-10-29')).to_dataframe()\n",
    "    \n",
    "    all_lats.append(obs_df['lat'][0])\n",
    "    all_lons.append(obs_df['lon'][0])\n",
    "    \n",
    "    # Create a pandas dataframe to store and plot the data\n",
    "    loc_flags = qc.location_set_check(arr_slice['lon'], arr_slice['lat'], bbox_arr=bbox)\n",
    "    obs_df['flags'] = loc_flags\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    obs_df['flags'].plot(ax=ax, color='k', title='Location QC Flag For Station '+station_id, ylim=[0,5])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations Shown on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[45.0,0], tiles='Mapbox Bright', zoom_start=2)\n",
    "folium.PolyLine(get_coordinates(np.asarray(bbox).reshape(-1)), color='#FF0000', weight=5).add_to(m)\n",
    "popup_string = ('<b>Station:</b><br>'+ station_ids[1])\n",
    "\n",
    "all_lats=np.asarray(all_lats)\n",
    "all_lons=np.asarray(all_lons)\n",
    "\n",
    "loc_flags = qc.location_set_check(all_lons, all_lats, bbox_arr=bbox, range_max=None)    \n",
    "\n",
    "for lat, lon in zip(all_lats, all_lons):\n",
    "    folium.Circle([lat, lon], color='purple', popup=popup_string).add_to(m)\n",
    "bad_vals = np.where(loc_flags>1)\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The flagged station has positive 86.968 for longitude which could be a sign error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gross Range test\n",
    "Given sensor minimum/maximum values, flag data that falls outside of range as bad data.  Optionally also flag data which falls outside of a user defined range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for station_id in station_ids:\n",
    "    file_url=Glos_url+station_id+'/'+station_id+'.ncml'\n",
    "    xr_dataset=xr.open_dataset(file_url)\n",
    "    \n",
    "    arr=xr_dataset.sel(time=slice('2017-10-22','2017-10-29')).variables\n",
    "    \n",
    "    arr_slice=xr_dataset.sel(time=slice('2017-10-22','2017-10-29'))\n",
    "    obs_df = xr_dataset.sel(time=slice('2017-10-22','2017-10-29')).to_dataframe()\n",
    "    \n",
    "\n",
    "    # Specify the gross range (0-2.8m for this demonstration)\n",
    "    gross_range = (0, 2.8)\n",
    "    range_flags = qc.range_check(arr_slice['Significant_Wave_Height'], gross_range)\n",
    "    # Create a pandas dataframe to store and plot the data\n",
    "\n",
    "    obs_df['flags'] = range_flags\n",
    "    obs_df['raw']=arr_slice['Significant_Wave_Height']\n",
    "        \n",
    "\n",
    "    fig, ax = plt.subplots(2,1,figsize=(16, 13))\n",
    "    flags = obs_df['flags'].plot(ax=ax[0], color='k', title='Gross Range QC Flag For Station '+station_id, ylim=[0,5])\n",
    "    raw = obs_df['raw'].plot(ax=ax[1], color='#87CEEB')\n",
    "    flags.set_ylabel(\"QC Flag\")\n",
    "    raw.set_ylabel(\"sea_surface_wave_significant_height (m)\")\n",
    "\n",
    "    bad_data = np.where(range_flags == 4)\n",
    "\n",
    "    bad_handle = ax[1].plot(arr_slice['time'][bad_data], arr_slice['Significant_Wave_Height'][bad_data], 'rd')\n",
    "    plt.legend(['raw', 'BAD_DATA'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike test\n",
    "Determine if there is a spike at data point n-1 by subtracting the midpoint of n and n-2 and taking the absolute value of this quantity, seeing if it exceeds a threshold for suspect and bad data. \n",
    "Values which do not exceed either threshold are flagged good, values which exceed the low threshold are flagged suspect, and values which exceed the high threshold are flagged bad. The flag is set at point n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in station_ids:\n",
    "    file_url=Glos_url+station_id+'/'+station_id+'.ncml'\n",
    "    xr_dataset=xr.open_dataset(file_url)\n",
    "    arr=xr_dataset.sel(time=slice('2017-10-22','2017-10-29')).variables\n",
    "\n",
    "    arr_slice=xr_dataset.sel(time=slice('2017-10-22','2017-10-29'))\n",
    "    obs_df = xr_dataset.sel(time=slice('2017-10-22','2017-10-29')).to_dataframe()\n",
    "\n",
    "\n",
    "    warning_threshold = 0.5 #0.9144\n",
    "    bad_threshold = 1 #1.524\n",
    "    spike_flags = qc.spike_check(arr_slice['Significant_Wave_Height'], warning_threshold, bad_threshold)\n",
    "       \n",
    "    # Create a pandas dataframe to store and plot the data\n",
    "    obs_df['flags'] = spike_flags\n",
    "    obs_df['raw']=arr_slice['Significant_Wave_Height']\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(2,1,figsize=(16, 13))\n",
    "    flags = obs_df['flags'].plot(ax=ax[0], color='k', title='Spike Test QC Flag For Station '+station_id, ylim=[0,5])\n",
    "       \n",
    "    good_data = np.where(spike_flags == 1)\n",
    "    suspect_data = np.where(spike_flags == 3)\n",
    "       \n",
    "    raw = obs_df['raw'].plot(ax=ax[1], color='#87CEEB')\n",
    "    raw.set_ylabel(\"sea_surface_wave_significant_height (m)\")\n",
    "    bad_data = np.where(range_flags == 4)\n",
    "\n",
    "    bad_handle = ax[1].plot(arr_slice['time'][suspect_data], arr_slice['Significant_Wave_Height'][suspect_data], 'kd')\n",
    "    bad_handle = ax[1].plot(arr_slice['time'][bad_data], arr_slice['Significant_Wave_Height'][bad_data], 'rd')\n",
    "    plt.legend(['raw', 'SUSPECT_DATA', 'BAD_DATA'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat Line test\n",
    "Check for repeated consecutively repeated values within a tolerance eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id in station_ids:\n",
    "    file_url=Glos_url+station_id+'/'+station_id+'.ncml'\n",
    "    xr_dataset=xr.open_dataset(file_url)\n",
    "    arr=xr_dataset.sel(time=slice('2017-10-22','2017-10-29')).variables\n",
    "\n",
    "    arr_slice=xr_dataset.sel(time=slice('2017-10-22','2017-10-29'))\n",
    "    obs_df = xr_dataset.sel(time=slice('2017-10-22','2017-10-29')).to_dataframe()\n",
    "    \n",
    "    tolerance = 0.003\n",
    "    rep_flags = qc.flat_line_check(arr_slice['Significant_Wave_Height'], 2, 6, tolerance)\n",
    "       \n",
    "    # Create a pandas dataframe to store and plot the data\n",
    "    obs_df['flags'] = rep_flags\n",
    "    obs_df['raw']=arr_slice['Significant_Wave_Height']\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(2,1,figsize=(16, 13))\n",
    "    flags = obs_df['flags'].plot(ax=ax[0], color='k', title='Flat Line Test QC Flag For Station '+station_id, ylim=[0,5])\n",
    "       \n",
    "    good_data = np.where(rep_flags == 1)\n",
    "    bad_data = np.where(rep_flags == 4)\n",
    "    suspect_data = np.where(rep_flags == 3)\n",
    "    \n",
    "    # Only plot the data near the suspect data to show the flat line\n",
    "    ax[1].plot(arr_slice['time'], arr_slice['Significant_Wave_Height'], '#87CEEB')\n",
    "    if suspect_data[0].size>0:\n",
    "        ax[1].plot(arr_slice['time'][suspect_data], arr_slice['Significant_Wave_Height'][suspect_data], 'kd')\n",
    "    if bad_data[0].size>0:\n",
    "        ax[1].plot(arr_slice['time'][bad_data], arr_slice['Significant_Wave_Height'][bad_data], 'rd')\n",
    "\n",
    "    ax[1].set_ylabel(\"sea_surface_wave_significant_height (m)\")\n",
    "    plt.legend(['raw', 'SUSPECT_DATA', 'BAD_DATA'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flagged values are when a significant wave height changes by less than 0.003 meters between time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
